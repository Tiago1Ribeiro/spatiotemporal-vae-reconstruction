{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 17:36:46.740908: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-03 17:36:46.765541: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-03 17:36:46.765565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-03 17:36:46.766261: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-03 17:36:46.770643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-03 17:36:47.254652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import time \n",
    "import cv2\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Lambda, Input, Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten, Reshape, Concatenate\n",
    "from tensorflow.keras.layers import SeparableConv2D, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Local Module Imports\n",
    "sys.path.append(\"../src\")  # adds source code directory\n",
    "from utils import load_images_from_folder, label_to_frame, frame_to_label\n",
    "from utils import frames_to_video\n",
    "from visualization import plot_learning_curves\n",
    "from polygon_handle import masks_to_polygons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "BASE_DIR = os.path.dirname(current_dir)\n",
    "dataset_dir = os.path.join(BASE_DIR, \"dataset\")\n",
    "data_dir = os.path.join(BASE_DIR, \"data\")\n",
    "config_file = os.path.join(BASE_DIR, \"config.yml\")\n",
    "\n",
    "\n",
    "# Operation Mode\n",
    "DATA = \"full\"  # \"full\" or \"sampled\" or \"reg_sampled\"\n",
    "MODE = \"extrapol\"  # \"interpol\" or \"extrapol\"\n",
    "PERCENTAGE = 0.8 \n",
    "\n",
    "output_png_dir = os.path.join(BASE_DIR, 'outputs', 'CVAE', MODE, DATA, 'PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks || Train: 226, Train sampled: 13 | Test: 23 |\n"
     ]
    }
   ],
   "source": [
    "# reconstruct the masks labels\n",
    "train_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"masks\")\n",
    "test_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"masks\")\n",
    "sampled_masks_txt_path = os.path.join(BASE_DIR, config[\"data\"][\"sampled_masks_txt\"])\n",
    "with open(sampled_masks_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    polygons = f.readlines()\n",
    "    # extract indexes\n",
    "    indexes = [int(polygon.split(\",\")[0]) for polygon in polygons]\n",
    "\n",
    "train_sampled_masks_dir = os.path.join(\n",
    "    BASE_DIR, config[\"data\"][\"train_sampled_dir\"], \"masks\"\n",
    ")\n",
    "\n",
    "msks_train_paths = sorted(glob(os.path.join(train_masks_dir, \"*.png\")))\n",
    "msks_train_labels = [\n",
    "    int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 for m in msks_train_paths\n",
    "]\n",
    "msks_test_paths = sorted(glob(os.path.join(test_masks_dir, \"*.png\")))\n",
    "msks_test_labels = [\n",
    "    int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 + 20250\n",
    "    for m in msks_test_paths\n",
    "]\n",
    "msks_train_sampled_paths = sorted(glob(os.path.join(train_sampled_masks_dir, \"*.png\")))\n",
    "msks_train_sampled_labels = [100 * i for i in indexes]\n",
    "\n",
    "print(\n",
    "    f\"Masks || Train: {len(msks_train_paths)}, Train sampled: {len(msks_train_sampled_paths)} | Test: {len(msks_test_paths)} |\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truncated training labels: 0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1899, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3299, 3400, 3500, 3600, 3700, 3799, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6599, 6700, 6800, 6900, 7000, 7099, 7200, 7300, 7400, 7500, 7599, 7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500, 9600, 9700, 9800, 9900, 10000, 10100, 10200, 10300, 10400, 10500, 10600, 10700, 10800, 10900, 11000, 11100, 11200, 11300, 11400, 11500, 11600, 11700, 11800, 11900, 12000, 12100, 12200, 12300, 12400, 12500, 12600, 12699, 12800, 12900, 13000, 13100, 13199, 13300, 13400, 13500, 13600, 13699, 13800, 13900, 14000, 14100, 14199, 14300, 14400, 14500, 14600, 14699, 14800, 14900, 15000, 15100, 15199, 15300, 15400, 15500, 15600, 15699, 15800, 15900, 16000, 16100, 16200, 16300, 16400, 16500, 16600, 16700, 16800, 16900, 17000, 17100, 17200, 17300, 17400, 17500, 17600, 17700, 17800, 17900, 18000, 18100, 18200, 18300, 18400, 18500, 18600, 18700, 18800, 18900, 19000, 19100, 19200, 19300, 19400, 19500, 19600, 19700, 19800, 19900, 20000, 20100, 20200, | Total No. of labels: 203\n",
      "\n",
      "----------------------------------------------------------\n",
      "Variable        Shape (N,H,W,C)    Dtype     Max     Min     \n",
      "----------------------------------------------------------\n",
      "train_imgs      (203, 512, 512, 1) float32   1.0    -1.0\n",
      "train_labels    (203, 1)           float32   0.9     0.0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "test_imgs       (23, 512, 512, 1)  float32   1.0    -1.0\n",
      "test_labels     (23, 1)            float32   1.0     0.9\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if DATA == \"full\":\n",
    "    TRAIN_DIR = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"masks\")\n",
    "    train_masks = load_images_from_folder(\n",
    "        TRAIN_DIR, target_size=config[\"data\"][\"input_size\"][:2]\n",
    "    )\n",
    "    # labels normalization and reshaping\n",
    "    max_val = np.max(msks_train_labels)\n",
    "    train_labels = (msks_train_labels / max_val).astype(np.float32)\n",
    "    train_labels = np.expand_dims(train_labels, axis=-1)\n",
    "else:\n",
    "    TRAIN_DIR = os.path.join(BASE_DIR, config[\"data\"][\"train_sampled_dir\"], \"masks\")\n",
    "    train_masks = load_images_from_folder(\n",
    "        TRAIN_DIR, target_size=config[\"data\"][\"input_size\"][:2]\n",
    "    )\n",
    "    # labels normalization and reshaping\n",
    "    max_val = np.max(msks_train_labels)\n",
    "    train_labels = (msks_train_sampled_labels / max_val).astype(np.float32)\n",
    "    train_labels = np.expand_dims(train_labels, axis=-1)\n",
    "\n",
    "if MODE == \"extrapol\":  # truncate the train set to aprox. 90% of the original size\n",
    "    train_masks = train_masks[: int(0.9 * len(train_masks))]\n",
    "    train_labels = train_labels[: int(0.9 * len(train_labels))]\n",
    "    # print each label number with label_to_frame\n",
    "    print(\"\\nTruncated training labels:\", end=' ')\n",
    "    for i in range(len(train_labels)):\n",
    "        print(label_to_frame(train_labels[i], max_val), end=', ')\n",
    "    print(f\"| Total No. of labels: {len(train_labels)}\\n\")\n",
    "\n",
    "\n",
    "TEST_DIR = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"masks\")\n",
    "test_masks = load_images_from_folder(\n",
    "    TEST_DIR, target_size=config[\"data\"][\"input_size\"][:2]\n",
    ")\n",
    "test_labels = (msks_test_labels / max_val).astype(np.float32)\n",
    "test_labels = np.expand_dims(test_labels, axis=-1)\n",
    "\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'Variable':<15} {'Shape (N,H,W,C)':<18} {'Dtype':<9} {'Max':<7} {'Min':<8}\")\n",
    "print(\"-\" * 58)\n",
    "print(\n",
    "    f\"{'train_imgs':<15} {str(train_masks.shape):<18} {str(train_masks.dtype):<8}  {np.max(train_masks):.1f}    {np.min(train_masks):.1f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'train_labels':<15} {str(train_labels.shape):<18} {str(train_labels.dtype):<8}  {np.max(train_labels):.1f}     {np.min(train_labels):.1f}\"\n",
    ")\n",
    "print(\"~\" * 58)\n",
    "print(\n",
    "    f\"{'test_imgs':<15} {str(test_masks.shape):<18} {str(test_masks.dtype):<8}  {np.max(test_masks):.1f}    {np.min(test_masks):.1f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'test_labels':<15} {str(test_labels.shape):<18} {str(test_labels.dtype):<8}  {np.max(test_labels):.1f}     {np.min(test_labels):.1f}\"\n",
    ")\n",
    "print(\"-\" * 58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-VAE definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(input, filters, f_init=\"he_normal\"):\n",
    "    \"\"\"\n",
    "    Apply two convolutional layers with ReLU activation function.\n",
    "\n",
    "    Args:\n",
    "          input (tensor): Input tensor to the block.\n",
    "          filters (int): Number of filters in the convolutional layers.\n",
    "\n",
    "    Returns:\n",
    "          tensor: Output tensor of the block with ReLU activation.\n",
    "    \"\"\"\n",
    "    x = Conv2DTranspose(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        strides=2,\n",
    "        kernel_initializer=f_init,\n",
    "        data_format=\"channels_last\",\n",
    "        padding=\"same\",\n",
    "    )(input)\n",
    "\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(x)\n",
    "    x = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(x)\n",
    "    activation = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    return activation\n",
    "\n",
    "def conv_block(input, filters, f_init=\"he_normal\"):\n",
    "    \"\"\"\n",
    "    Apply two convolutional layers with ReLU activation function.\n",
    "\n",
    "    Args:\n",
    "        input (tensor): Input tensor to the block.\n",
    "        filters (int): Number of filters in the convolutional layers.\n",
    "\n",
    "    Returns:\n",
    "        tensor: Output tensor of the block with ReLU activation.\n",
    "    \"\"\"\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(input)\n",
    "    x = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(x)\n",
    "    ativ = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    m_pool = MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=2, data_format=\"channels_last\", padding=\"same\"\n",
    "    )(ativ)\n",
    "\n",
    "    return m_pool\n",
    "\n",
    "def sampler(args):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    \n",
    "    Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def mse_kl_loss(y_true, y_pred, beta: float = 1.0):\n",
    "    \"\"\"Calculate loss = reconstruction loss + KL loss for each data in minibatch\"\"\"\n",
    "    # E[log P(X|z)]\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    reconstruction = tf.reduce_mean(squared_difference, axis=-1)\n",
    "    # D_KL(Q(z|X) || P(z|X)); calculate in closed from as both dist. are Gaussian\n",
    "    kl_divergence = 0.5 * tf.reduce_sum(\n",
    "        tf.exp(z_log_var) + tf.square(z_mean) - 1.0 - z_log_var, axis=-1\n",
    "    )\n",
    "    return reconstruction + beta * kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cvae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " encoder (Functional)        [(None, 64),                 3357281   ['input_2[0][0]']             \n",
      "                              (None, 64),                 6                                       \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " label (InputLayer)          [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " decoder (Functional)        (None, 512, 512, 1)          1749779   ['encoder[0][2]',             \n",
      "                                                          3          'label[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51070609 (194.82 MB)\n",
      "Trainable params: 51070609 (194.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "H, W, C = config[\"data\"][\"input_size\"]\n",
    "\n",
    "# --------\n",
    "# Encoder\n",
    "# --------\n",
    "\n",
    "encoder_inputs = Input(shape=(H, W, C))\n",
    "# Reshape input to 2D image\n",
    "\n",
    "x = conv_block(\n",
    "    encoder_inputs, config[\"CVAE\"][\"ref_filters\"] * 2, config[\"CVAE\"][\"w_init\"]\n",
    ")\n",
    "x = conv_block(x, config[\"CVAE\"][\"ref_filters\"] * 1, config[\"CVAE\"][\"w_init\"])\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation=\"leaky_relu\")(x)\n",
    "\n",
    "# VAE specific layers for mean and log variance\n",
    "z_mean = Dense(config[\"CVAE\"][\"latent_dim\"], activation=\"leaky_relu\", name=\"z_mean\")(x)\n",
    "z_log_var = Dense(\n",
    "    config[\"CVAE\"][\"latent_dim\"], activation=\"leaky_relu\", name=\"z_log_var\"\n",
    ")(x)\n",
    "\n",
    "# Sampling layer to sample z from the latent space\n",
    "z = Lambda(sampler, output_shape=(config[\"CVAE\"][\"latent_dim\"],), name=\"z\")(\n",
    "    [z_mean, z_log_var]\n",
    ")\n",
    "\n",
    "# Instantiate encoder model\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "# --------\n",
    "# Decoder\n",
    "# --------\n",
    "\n",
    "latent_inputs = Input(shape=(config[\"CVAE\"][\"latent_dim\"],), name=\"z_sampling\")\n",
    "label_size = len(train_labels[0])\n",
    "label_inputs = Input(shape=(label_size,), name=\"label\")\n",
    "decoder_inputs = Concatenate()([latent_inputs, label_inputs])\n",
    "x = Dense(64 * 64 * 64, activation=\"leaky_relu\")(decoder_inputs)\n",
    "x = Reshape((128, 128, 16))(x)\n",
    "x = deconv_block(x, config[\"CVAE\"][\"ref_filters\"] * 2, config[\"CVAE\"][\"w_init\"])\n",
    "x = deconv_block(x, config[\"CVAE\"][\"ref_filters\"] * 4, config[\"CVAE\"][\"w_init\"])\n",
    "decoder_output = Conv2DTranspose(1, 3, activation=\"tanh\", padding=\"same\")(x)\n",
    "\n",
    "decoder = Model([latent_inputs, label_inputs], decoder_output, name=\"decoder\")\n",
    "\n",
    "# -----------------\n",
    "# Conditional VAE\n",
    "# -----------------\n",
    "\n",
    "outputs = decoder([encoder(encoder_inputs)[2], label_inputs])\n",
    "cvae = Model([encoder_inputs, label_inputs], outputs, name=\"cvae\")\n",
    "cvae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\", factor=0.5, mode=\"min\", patience=30, verbose=1, min_lr=1e-8\n",
    ")\n",
    "\n",
    "checkpoint_dir = os.path.join(BASE_DIR, config[\"data\"][\"checkpoint_dir\"])\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir, f\"cvae_{DATA}_{MODE}.h5\")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    mode=\"auto\",\n",
    "    verbose=1,\n",
    "    monitor=\"loss\",\n",
    ")\n",
    "\n",
    "cvae.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=config[\"CVAE\"][\"learning_rate\"]), loss=mse_kl_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.optimizer.lr = config[\"CVAE\"][\"learning_rate\"]\n",
    "\n",
    "history = cvae.fit(\n",
    "    [train_masks, train_labels],\n",
    "    train_masks,\n",
    "    epochs=config[\"CVAE\"][\"epochs\"],\n",
    "    batch_size=1,\n",
    "    validation_data=([test_masks, test_labels], test_masks),\n",
    "    callbacks=[reduce_lr, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history, log_scale=True)\n",
    "save_history(history, os.path.join(checkpoint_dir, f\"history_{DATA}_{MODE}.log\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "cvae.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frames(\n",
    "    decoder, output_dir: str, total_frames: int = 22500, resize_original: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates and saves the frames from a trained decoder.\n",
    "\n",
    "    Parameters:\n",
    "        decoder (keras.Model): The trained decoder.\n",
    "        output_dir (str): The path to the output directory.\n",
    "        total_frames (int): The total number of frames to generate.\n",
    "        resize_original (bool): Whether to resize the frames to the original dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    start_total_time = time.time()\n",
    "\n",
    "    frames_num = np.arange(1, total_frames + 1, 1)\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        frame_num = frames_num[i]\n",
    "\n",
    "        # Sample from the latent space\n",
    "        z_sample = np.full((1, config[\"CVAE\"][\"latent_dim\"]), 0.5)\n",
    "\n",
    "        # Generate the frame\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            reconst = decoder.predict([z_sample, frame_to_label(frame_num)])\n",
    "            reconst_time = (time.time() - start_time) * 1000\n",
    "            reconst = np.squeeze(reconst, axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating frame {frame_num}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if resize_original:\n",
    "            start_time = time.time()\n",
    "            reconst = tf.image.resize(\n",
    "                images=reconst, size=config[\"data\"][\"original_vid_dims\"]\n",
    "            )\n",
    "            resize_time = (time.time() - start_time) * 1000\n",
    "        else:\n",
    "            resize_time = 0.0  # Not resizing\n",
    "\n",
    "        # Binarize the reconstructed image with OpenCV\n",
    "        start_time = time.time()\n",
    "        _, thresh_img = cv2.threshold(\n",
    "            reconst, config[\"CVAE\"][\"threshold\"], 255, cv2.THRESH_BINARY\n",
    "        )\n",
    "        threshold_time = (time.time() - start_time) * 1000\n",
    "\n",
    "        # Save the thresholded image as png in grayscale\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            cv2.imwrite(\n",
    "                os.path.join(output_dir, f\"frame_{frame_num:06d}.png\"), thresh_img\n",
    "            )\n",
    "            save_time = (time.time() - start_time) * 1000\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving frame {frame_num}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Print progress with time information\n",
    "        print(\n",
    "            f\"Generated frame {i+1} of {total_frames} | \"\n",
    "            f\"Reconst: {reconst_time:.2f}ms | \"\n",
    "            f\"Resize: {resize_time:.2f}ms | \"\n",
    "            f\"Threshold: {threshold_time:.2f}ms | \"\n",
    "            f\"Save: {save_time:.2f}ms | \"\n",
    "            f\"Elapsed Time: {time.time() - start_total_time:.2f}s  \",\n",
    "            end=\"\\r\",\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_frames(decoder, output_png_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate video from the generated frames\n",
    "title = f\"CVAE: {MODE}ation - {DATA}, {config['CVAE']['epochs']} epochs, 10x speed\"\n",
    "file_name = f\"video_{DATA}_{MODE}\"\n",
    "output_dir = os.path.join(BASE_DIR, \"outputs\", \"CVAE\", MODE, DATA)\n",
    "\n",
    "frames_to_video(\n",
    "    img_list_dir=output_png_dir,\n",
    "    output_dir=output_dir,\n",
    "    output_resolution=config[\"data\"][\"original_vid_dims\"],\n",
    "    title=title,\n",
    "    f_ps= 250,\n",
    "    file_name=f\"video_{DATA}_{MODE}\",\n",
    "    frame_num_text=True,\n",
    "    font_size=1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE, DATA = \"interpol\", \"full\"\n",
    "output_png_dir = os.path.join(BASE_DIR, 'outputs', 'CVAE', MODE, DATA, 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15644 masks out of 22501 | Time elapsed: 8154.48s  \r"
     ]
    }
   ],
   "source": [
    "# List of generated frames paths\n",
    "msks_paths = sorted(glob(os.path.join(output_png_dir, \"*.png\")))\n",
    "\n",
    "# Convert the masks to polygons and save them as a WKT file\n",
    "polygons = masks_to_polygons(\n",
    "    msks_paths,\n",
    "    out_dim=tuple(config[\"data\"][\"original_vid_dims\"]),\n",
    "    save_path=os.path.join(BASE_DIR, config[\"outputs\"][MODE][DATA], \"WKT\", f\"{MODE}_{DATA}.wkt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Value\n",
    "from multiprocessing import cpu_count\n",
    "from time import sleep\n",
    "from os import cpu_count\n",
    "from time import time\n",
    "from functools import partial\n",
    "\n",
    "def resize_image(img_path, counter, out_dim=(512, 512)):\n",
    "    try:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        h, w = img.shape\n",
    "        if (w, h) != out_dim:\n",
    "            img = cv2.resize(img, out_dim, interpolation=cv2.INTER_CUBIC)\n",
    "        return mask_to_poly(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "    finally:\n",
    "        with counter.get_lock():\n",
    "            counter.value += 1\n",
    "        print(f\"Processed {counter.value} masks\")\n",
    "\n",
    "def masks_to_polygons_v2(msks_paths: list, out_dim: tuple = (512, 512), save_path: str = None) -> list:\n",
    "    start_time = time.time()\n",
    "    counter = Value('i', 0)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "        futures = {executor.submit(resize_image, img_path, counter, out_dim): img_path for img_path in msks_paths}\n",
    "\n",
    "    # Collect results in order\n",
    "    pol_list = [future.result() for future in futures]\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Processed {len(msks_paths)} masks | Time elapsed: {elapsed_time:.2f}s\")\n",
    "\n",
    "    if save_path:\n",
    "        save_polygons_to_wkt(pol_list, save_path)\n",
    "        print(f\"Saved polygons to {save_path}\")\n",
    "\n",
    "    return pol_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
