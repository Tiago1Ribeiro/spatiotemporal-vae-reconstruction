{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Lambda, Input, Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten, Reshape, Concatenate\n",
    "from tensorflow.keras.layers import SeparableConv2D, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "disable_eager_execution()\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Local Module Imports\n",
    "sys.path.append(\"../src\")  # adds source code directory\n",
    "from utils import frame_to_label\n",
    "from utils import frames_to_video, save_history\n",
    "from visualization import plot_learning_curves\n",
    "from polygon_handle import masks_to_polygons\n",
    "from log_setup import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "DATA: \"full\" (full dataset), \"sampled\" (distance sampled dataset) \n",
    "        or \"unet\" (unet generated dataset)\n",
    "MODE: \"interpol\" (interpolation) or \"extrapol\" (extrapolation)\n",
    "MODEL: \"CVAE\"\n",
    "PERCENTAGE: percentage of training data to be used for training\n",
    "LAST_FRAME: last frame number of the video\n",
    "\"\"\"\n",
    "\n",
    "DATA = \"full\"\n",
    "MODE = \"extrapol\"\n",
    "MODEL = \"CVAE\"\n",
    "PERCENTAGE = 50\n",
    "LAST_FRAME = 22500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Data: full, Mode: extrapol, Model: CVAE Percentage: 50%,\n",
      "Output directory: /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/outputs/CVAE/extrapol/50/full\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "dataset_dir = os.path.join(BASE_DIR, \"dataset\")\n",
    "data_dir = os.path.join(BASE_DIR, \"data\")\n",
    "config_file = os.path.join(BASE_DIR, \"config.yml\")\n",
    "\n",
    "# Output PNG directory\n",
    "if MODE == \"extrapol\":\n",
    "    output_dir = os.path.join(BASE_DIR, \"outputs\", \"CVAE\", MODE, str(PERCENTAGE), DATA)\n",
    "    logger.info(\n",
    "        f\"Data: {DATA}, Mode: {MODE}, Model: {MODEL} Percentage: {PERCENTAGE}%,\\nOutput directory: {output_dir}\"\n",
    "    )\n",
    "elif MODE == \"interpol\":\n",
    "    output_dir = os.path.join(BASE_DIR, \"outputs\", \"CVAE\", MODE, DATA)\n",
    "    logger.info(\n",
    "        f\"\\nData: {DATA}, Mode: {MODE}, Model: {MODEL}\\nOutput directory: {output_dir}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - No. train. samples: 113 out of 22500 (50%) | No. test samples: 23\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "if DATA == \"full\":\n",
    "    train_dir = os.path.join(BASE_DIR, config[\"data\"][\"full\"][\"train_dir\"], \"masks\")\n",
    "    # sort the paths\n",
    "    train_paths = sorted(glob(os.path.join(train_dir, \"*.png\")))\n",
    "    # extract labels from the paths\n",
    "    train_labels = [\n",
    "        int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 for m in train_paths\n",
    "    ]\n",
    "    epochs = config[\"CVAE\"][\"epochs\"]\n",
    "\n",
    "elif DATA == \"sampled\":\n",
    "    sampled_masks_txt_path = os.path.join(BASE_DIR, config[\"data\"][\"sampled_masks_txt\"])\n",
    "    with open(sampled_masks_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        polygons = f.readlines()\n",
    "        # extract indexes\n",
    "    indexes = [int(polygon.split(\",\")[0]) for polygon in polygons]\n",
    "    train_dir = os.path.join(BASE_DIR, config[\"data\"][\"sampled\"][\"train_dir\"], \"masks\")\n",
    "    train_paths = sorted(glob(os.path.join(train_dir, \"*.png\")))\n",
    "    train_labels = [100 * i for i in indexes]\n",
    "    epochs = config[\"CVAE\"][\"epochs\"]\n",
    "\n",
    "elif DATA == \"unet\":\n",
    "    train_dir = os.path.join(BASE_DIR, config[\"data\"][\"unet\"][\"train_dir\"], \"masks\")\n",
    "    train_paths = sorted(glob(os.path.join(train_dir, \"*.png\")))\n",
    "    train_labels = [\n",
    "        int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) for m in train_paths\n",
    "    ]\n",
    "    epochs = 2\n",
    "\n",
    "\n",
    "# Test data\n",
    "test_dir = os.path.join(BASE_DIR, config[\"data\"][\"test\"][\"test_dir\"], \"masks\")\n",
    "test_paths = sorted(glob(os.path.join(test_dir, \"*.png\")))\n",
    "test_labels = [\n",
    "    int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 + 20250\n",
    "    for m in test_paths\n",
    "]\n",
    "\n",
    "if MODE == \"extrapol\":\n",
    "    # Truncate the training data\n",
    "    train_paths = train_paths[: int(len(train_paths) * PERCENTAGE / 100)]\n",
    "    train_labels = train_labels[: int(len(train_labels) * PERCENTAGE / 100)]\n",
    "    logger.info(f\"No. train. samples: {len(train_paths)} out of {LAST_FRAME} ({PERCENTAGE}%) | No. test samples: {len(test_paths)}\")\n",
    "elif MODE == \"interpol\":\n",
    "    logger.info(f\"No. train. samples: {len(train_paths)} out of {LAST_FRAME} | No. test samples: {len(test_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAEDataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    A data generator for the Conditional Variational Autoencoder (CVAE) model.\n",
    "\n",
    "    This class generates batches of images and corresponding labels from a given set of data paths and labels.\n",
    "    It shuffles the data at the end of each epoch to ensure that the model sees all data in each epoch.\n",
    "\n",
    "    Attributes:\n",
    "        data_paths: A list of paths to the data files.\n",
    "        labels: A list of corresponding labels for the data files.\n",
    "        batch_size: The number of samples per gradient update.\n",
    "        input_shape: The shape of the input data.\n",
    "        num_frames: The total number of frames in the data.\n",
    "\n",
    "    Methods:\n",
    "        __init__: Initializes the data generator.\n",
    "        __len__: Returns the number of batches in the data.\n",
    "        __getitem__: Returns a batch of images and labels.\n",
    "        on_epoch_end: Shuffles the data at the end of each epoch.\n",
    "        load_and_preprocess_data: Loads and preprocesses a batch of images and labels.\n",
    "        load_preprocess_mask: Loads and preprocesses a single mask image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_paths, labels, batch_size, input_shape, last_frame):\n",
    "        \"\"\"\n",
    "        Initializes the data generator.\n",
    "\n",
    "        Args:\n",
    "            data_paths: A list of paths to the data files.\n",
    "            labels: A list of corresponding labels for the data files.\n",
    "            batch_size: The number of samples per gradient update.\n",
    "            input_shape: The shape of the input data.\n",
    "            last_frame: The total number of frames in the data.\n",
    "        \"\"\"\n",
    "        self.data_paths = data_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.num_frames = last_frame\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of batches in the data.\n",
    "\n",
    "        Returns:\n",
    "            The number of batches in the data.\n",
    "        \"\"\"\n",
    "        return int(np.ceil(len(self.data_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a batch of images and labels.\n",
    "\n",
    "        Args:\n",
    "            index: The index of the batch.\n",
    "\n",
    "        Returns:\n",
    "            A batch of images and labels.\n",
    "        \"\"\"\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = (index + 1) * self.batch_size\n",
    "        batch_data_paths = self.data_paths[start_idx:end_idx]\n",
    "        batch_labels = self.labels[start_idx:end_idx]\n",
    "\n",
    "        batch_images, batch_labels = self.load_and_preprocess_data(\n",
    "            batch_data_paths, batch_labels\n",
    "        )\n",
    "        return [batch_images, batch_labels], batch_images\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Shuffles the data at the end of each epoch.\n",
    "        \"\"\"\n",
    "        indices = np.arange(len(self.data_paths))\n",
    "        np.random.shuffle(indices)\n",
    "        self.data_paths = [self.data_paths[i] for i in indices]\n",
    "        self.labels = [self.labels[i] for i in indices]\n",
    "\n",
    "    def load_and_preprocess_data(self, batch_data_paths, batch_labels):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses a batch of images and labels.\n",
    "\n",
    "        Args:\n",
    "            batch_data_paths: A list of paths to the data files.\n",
    "            batch_labels: A list of corresponding labels for the data files.\n",
    "\n",
    "        Returns:\n",
    "            A batch of images and labels.\n",
    "        \"\"\"\n",
    "        batch_images = []\n",
    "        batch_labels_processed = []\n",
    "        for data_path, label in zip(batch_data_paths, batch_labels):\n",
    "            image, label = self.load_preprocess_mask(\n",
    "                data_path, label, self.input_shape, self.num_frames\n",
    "            )\n",
    "            batch_images.append(image)\n",
    "            batch_labels_processed.append(label)\n",
    "        return np.array(batch_images), np.array(batch_labels_processed)\n",
    "\n",
    "    def load_preprocess_mask(self, mask_path, label, output_dims, last_frame):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses a single mask image.\n",
    "\n",
    "        Args:\n",
    "            mask_path: The path to the mask file.\n",
    "            label: The corresponding label for the mask file.\n",
    "            output_dims: The desired dimensions of the mask.\n",
    "            last_frame: The total number of frames in the data.\n",
    "\n",
    "        Returns:\n",
    "            A preprocessed mask image and its corresponding label.\n",
    "        \"\"\"\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(mask_path):\n",
    "            raise FileNotFoundError(f\"No such file: '{mask_path}'\")\n",
    "\n",
    "        # Read and decode the image\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize the image\n",
    "        mask = cv2.resize(mask, output_dims)\n",
    "\n",
    "        # Add channel dimension\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "        # Normalize the mask\n",
    "        mask = (mask / 127.5) - 1\n",
    "\n",
    "        # Normalize the label\n",
    "        label = label / last_frame\n",
    "        label = np.expand_dims(label, axis=-1)\n",
    "\n",
    "        return mask, label\n",
    "\n",
    "\n",
    "input_shape = config[\"CVAE\"][\"input_shape\"]\n",
    "\n",
    "# Create training data generator\n",
    "train_data_gen = CVAEDataGenerator(\n",
    "    data_paths=train_paths,\n",
    "    labels=train_labels,\n",
    "    batch_size=1,\n",
    "    input_shape=input_shape[:2],\n",
    "    last_frame=LAST_FRAME,\n",
    ")\n",
    "\n",
    "# Create testing data generator\n",
    "test_data_gen = CVAEDataGenerator(\n",
    "    data_paths=test_paths,\n",
    "    labels=test_labels,\n",
    "    batch_size=1,\n",
    "    input_shape=input_shape[:2],\n",
    "    last_frame=LAST_FRAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-VAE definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(input, filters, f_init=\"he_normal\"):\n",
    "    \"\"\"\n",
    "    Apply two convolutional layers with ReLU activation function.\n",
    "\n",
    "    Args:\n",
    "        input (tensor): Input tensor to the block.\n",
    "        filters (int): Number of filters in the convolutional layers.\n",
    "\n",
    "    Returns:\n",
    "        tensor: Output tensor of the block with ReLU activation.\n",
    "    \"\"\"\n",
    "    x = Conv2DTranspose(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        strides=2,\n",
    "        kernel_initializer=f_init,\n",
    "        data_format=\"channels_last\",\n",
    "        padding=\"same\",\n",
    "    )(input)\n",
    "\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(x)\n",
    "    x = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(x)\n",
    "    activation = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    return activation\n",
    "\n",
    "\n",
    "def conv_block(input, filters, f_init=\"he_normal\"):\n",
    "    \"\"\"\n",
    "    Apply two convolutional layers with ReLU activation function.\n",
    "\n",
    "    Args:\n",
    "        input (tensor): Input tensor to the block.\n",
    "        filters (int): Number of filters in the convolutional layers.\n",
    "\n",
    "    Returns:\n",
    "        tensor: Output tensor of the block with ReLU activation.\n",
    "    \"\"\"\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(input)\n",
    "    x = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    x = SeparableConv2D(\n",
    "        filters,\n",
    "        kernel_size=(4, 4),\n",
    "        depthwise_initializer=f_init,\n",
    "        pointwise_initializer=f_init,\n",
    "        padding=\"same\",\n",
    "    )(x)\n",
    "    ativ = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    m_pool = MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=2, data_format=\"channels_last\", padding=\"same\"\n",
    "    )(ativ)\n",
    "\n",
    "    return m_pool\n",
    "\n",
    "\n",
    "def sampler(args):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "\n",
    "    Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def mse_kl_loss(y_true, y_pred, beta: float = 1.0):\n",
    "    \"\"\"Calculate loss = reconstruction loss + KL loss for each data in minibatch\"\"\"\n",
    "    # E[log P(X|z)]\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    reconstruction = tf.reduce_mean(squared_difference, axis=-1)\n",
    "    # D_KL(Q(z|X) || P(z|X)); calculate in closed from as both dist. are Gaussian\n",
    "    kl_divergence = 0.5 * tf.reduce_sum(\n",
    "        tf.exp(z_log_var) + tf.square(z_mean) - 1.0 - z_log_var, axis=-1\n",
    "    )\n",
    "    return reconstruction + beta * kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cvae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " encoder (Functional)        [(None, 64),                 3357281   ['input_1[0][0]']             \n",
      "                              (None, 64),                 6                                       \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " label (InputLayer)          [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " decoder (Functional)        (None, 512, 512, 1)          1749779   ['encoder[0][2]',             \n",
      "                                                          3          'label[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51070609 (194.82 MB)\n",
      "Trainable params: 51070609 (194.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "H, W, C = config[\"CVAE\"][\"input_shape\"]\n",
    "\n",
    "# --------\n",
    "# Encoder\n",
    "# --------\n",
    "\n",
    "encoder_inputs = Input(shape=(H, W, C))\n",
    "# Reshape input to 2D image\n",
    "\n",
    "x = conv_block(\n",
    "    encoder_inputs, config[\"CVAE\"][\"ref_filters\"] * 2, config[\"CVAE\"][\"w_init\"]\n",
    ")\n",
    "x = conv_block(x, config[\"CVAE\"][\"ref_filters\"] * 1, config[\"CVAE\"][\"w_init\"])\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation=\"leaky_relu\")(x)\n",
    "\n",
    "# VAE specific layers for mean and log variance\n",
    "z_mean = Dense(config[\"CVAE\"][\"latent_dim\"], activation=\"leaky_relu\", name=\"z_mean\")(x)\n",
    "z_log_var = Dense(\n",
    "    config[\"CVAE\"][\"latent_dim\"], activation=\"leaky_relu\", name=\"z_log_var\"\n",
    ")(x)\n",
    "\n",
    "# Sampling layer to sample z from the latent space\n",
    "z = Lambda(sampler, output_shape=(config[\"CVAE\"][\"latent_dim\"],), name=\"z\")(\n",
    "    [z_mean, z_log_var]\n",
    ")\n",
    "\n",
    "# Instantiate encoder model\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "# --------\n",
    "# Decoder\n",
    "# --------\n",
    "\n",
    "latent_inputs = Input(shape=(config[\"CVAE\"][\"latent_dim\"],), name=\"z_sampling\")\n",
    "label_size = 1 # one tf.float32 label\n",
    "label_inputs = Input(shape=(label_size,), name=\"label\")\n",
    "decoder_inputs = Concatenate()([latent_inputs, label_inputs])\n",
    "x = Dense(64 * 64 * 64, activation=\"leaky_relu\")(decoder_inputs)\n",
    "x = Reshape((128, 128, 16))(x)\n",
    "x = deconv_block(x, config[\"CVAE\"][\"ref_filters\"] * 2, config[\"CVAE\"][\"w_init\"])\n",
    "x = deconv_block(x, config[\"CVAE\"][\"ref_filters\"] * 4, config[\"CVAE\"][\"w_init\"])\n",
    "decoder_output = Conv2DTranspose(1, 3, activation=\"tanh\", padding=\"same\")(x)\n",
    "\n",
    "decoder = Model([latent_inputs, label_inputs], decoder_output, name=\"decoder\")\n",
    "\n",
    "# -----------------\n",
    "# Conditional VAE\n",
    "# -----------------\n",
    "\n",
    "outputs = decoder([encoder(encoder_inputs)[2], label_inputs])\n",
    "cvae = Model([encoder_inputs, label_inputs], outputs, name=\"cvae\")\n",
    "cvae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceLROnPlateauSteps(tf.keras.callbacks.ReduceLROnPlateau):\n",
    "    def __init__(\n",
    "        self, monitor=\"val_loss\", factor=0.5, patience=500, min_lr=1e-8, **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            monitor=monitor, factor=factor, patience=patience, min_lr=min_lr, **kwargs\n",
    "        )\n",
    "        self.wait = 0\n",
    "        self.best = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        current = self.get_monitor_value(logs)\n",
    "        if current < self.best:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.wait = 0\n",
    "                new_lr = self.model.optimizer.learning_rate * self.factor\n",
    "                new_lr = tf.keras.backend.get_value(new_lr)\n",
    "                self.model.optimizer.learning_rate = new_lr\n",
    "                print(\"Reducing learning rate to %s.\" % (new_lr,))\n",
    "\n",
    "    def get_monitor_value(self, logs):\n",
    "        logs = logs or {}\n",
    "        monitor_value = logs.get(self.monitor)\n",
    "        if monitor_value is None:\n",
    "            logger.warning(\n",
    "                \"Learning rate reduction on plateau conditioned on metric `%s` \"\n",
    "                \"which is not available. Available metrics are: %s\"\n",
    "                % (self.monitor, \", \".join(list(logs.keys()))),\n",
    "                RuntimeWarning,\n",
    "            )\n",
    "        return monitor_value\n",
    "\n",
    "\n",
    "class EarlyStoppingSteps(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, monitor=\"val_loss\", min_delta=0, patience=500, **kwargs):\n",
    "        super().__init__(\n",
    "            monitor=monitor, min_delta=min_delta, patience=patience, **kwargs\n",
    "        )\n",
    "        self.wait = 0\n",
    "        self.best = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        \"\"\"\n",
    "        At the end of each batch, check if the monitored quantity has improved.\n",
    "        If number of batches since the last improvement is more than the patience,\n",
    "        stop training.\n",
    "        \"\"\"\n",
    "        current = self.get_monitor_value(logs)\n",
    "        if current < self.best:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.wait = 0\n",
    "                self.stopped_epoch = self.model.history.epoch[-1]\n",
    "                self.model.stop_training = True\n",
    "                print(\"Early stopping\")\n",
    "\n",
    "    def get_monitor_value(self, logs):\n",
    "        logs = logs or {}\n",
    "        monitor_value = logs.get(self.monitor)\n",
    "        if monitor_value is None:\n",
    "            logger.warning(\n",
    "                \"Early stopping conditioned on metric `%s` \"\n",
    "                \"which is not available. Available metrics are: %s\"\n",
    "                % (self.monitor, \", \".join(list(logs.keys()))),\n",
    "                RuntimeWarning,\n",
    "            )\n",
    "        return monitor_value\n",
    "\n",
    "\n",
    "class ModelCheckpointSteps(tf.keras.callbacks.ModelCheckpoint):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False,\n",
    "        mode=\"auto\",\n",
    "        verbose=0,\n",
    "        save_freq=\"epoch\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            filepath=filepath,\n",
    "            monitor=monitor,\n",
    "            save_best_only=save_best_only,\n",
    "            save_weights_only=save_weights_only,\n",
    "            mode=mode,\n",
    "            verbose=verbose,\n",
    "            save_freq=save_freq,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.step_count = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.step_count += 1\n",
    "        if self.step_count % self.save_freq == 0:\n",
    "            self.save_weights(self.filepath, overwrite=True)\n",
    "\n",
    "\n",
    "class HistoryLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_interval):\n",
    "        super().__init__()\n",
    "        self.log_interval = log_interval\n",
    "        self.step_count = 0\n",
    "        self.history = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.step_count += 1\n",
    "        if self.step_count % self.log_interval == 0:\n",
    "            self.history.append(logs)\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateauSteps(\n",
    "    monitor=\"loss\", factor=0.5, mode=\"min\", patience=5000, verbose=1, min_lr=1e-8\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingSteps(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=0,\n",
    "    patience=10000,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "checkpoint_dir = os.path.join(BASE_DIR, config[\"data\"][\"checkpoint_dir\"])\n",
    "if MODE == \"extrapol\":\n",
    "    checkpoint_path = os.path.join(\n",
    "        checkpoint_dir, f\"cvae_{DATA}_{MODE}_{PERCENTAGE}.h5\"\n",
    "    )\n",
    "elif MODE == \"interpol\":\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"cvae_{DATA}_{MODE}.h5\")\n",
    "\n",
    "# use ModelCheckpoint to save best model\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    monitor=\"loss\",\n",
    "    mode=\"auto\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "history_logger = HistoryLogger(log_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(\n",
    "        learning_rate=config[\"CVAE\"][\"learning_rate\"]\n",
    "    ),\n",
    "    loss=mse_kl_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.7527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagociic/miniconda3/envs/cvae/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: loss improved from inf to 0.75274, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 27s 160ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.7527 - val_loss: 0.9514 - lr: 3.0000e-04\n",
      "Epoch 2/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.3117\n",
      "Epoch 2: loss improved from 0.75274 to 0.31165, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 18s 155ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.3117 - val_loss: 0.7230 - lr: 3.0000e-04\n",
      "Epoch 3/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.2068\n",
      "Epoch 3: loss improved from 0.31165 to 0.20677, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 18s 155ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.2068 - val_loss: 0.7344 - lr: 3.0000e-04\n",
      "Epoch 4/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.2109\n",
      "Epoch 4: loss did not improve from 0.20677\n",
      "113/113 [==============================] - 17s 154ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.2109 - val_loss: 0.7256 - lr: 3.0000e-04\n",
      "Epoch 5/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1773\n",
      "Epoch 5: loss improved from 0.20677 to 0.17726, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 17s 152ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1773 - val_loss: 0.7140 - lr: 3.0000e-04\n",
      "Epoch 6/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1772\n",
      "Epoch 6: loss improved from 0.17726 to 0.17724, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 17s 146ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1772 - val_loss: 0.6548 - lr: 3.0000e-04\n",
      "Epoch 7/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1703\n",
      "Epoch 7: loss improved from 0.17724 to 0.17030, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 141ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1703 - val_loss: 0.6646 - lr: 3.0000e-04\n",
      "Epoch 8/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1536\n",
      "Epoch 8: loss improved from 0.17030 to 0.15358, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 143ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1536 - val_loss: 0.6081 - lr: 3.0000e-04\n",
      "Epoch 9/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1552\n",
      "Epoch 9: loss did not improve from 0.15358\n",
      "113/113 [==============================] - 16s 142ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1552 - val_loss: 0.6143 - lr: 3.0000e-04\n",
      "Epoch 10/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1555\n",
      "Epoch 10: loss did not improve from 0.15358\n",
      "113/113 [==============================] - 16s 142ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1555 - val_loss: 0.6114 - lr: 3.0000e-04\n",
      "Epoch 11/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1364\n",
      "Epoch 11: loss improved from 0.15358 to 0.13639, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 145ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1364 - val_loss: 0.5914 - lr: 3.0000e-04\n",
      "Epoch 12/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1437\n",
      "Epoch 12: loss did not improve from 0.13639\n",
      "113/113 [==============================] - 16s 142ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1437 - val_loss: 0.5803 - lr: 3.0000e-04\n",
      "Epoch 13/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1275\n",
      "Epoch 13: loss improved from 0.13639 to 0.12754, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 144ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1275 - val_loss: 0.5843 - lr: 3.0000e-04\n",
      "Epoch 14/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1320\n",
      "Epoch 14: loss did not improve from 0.12754\n",
      "113/113 [==============================] - 16s 143ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1320 - val_loss: 0.5773 - lr: 3.0000e-04\n",
      "Epoch 15/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1272\n",
      "Epoch 15: loss improved from 0.12754 to 0.12723, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 140ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1272 - val_loss: 0.5740 - lr: 3.0000e-04\n",
      "Epoch 16/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1221\n",
      "Epoch 16: loss improved from 0.12723 to 0.12212, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 141ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1221 - val_loss: 0.5679 - lr: 3.0000e-04\n",
      "Epoch 17/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1222\n",
      "Epoch 17: loss did not improve from 0.12212\n",
      "113/113 [==============================] - 16s 144ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1222 - val_loss: 0.5691 - lr: 3.0000e-04\n",
      "Epoch 18/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1266\n",
      "Epoch 18: loss did not improve from 0.12212\n",
      "113/113 [==============================] - 16s 142ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1266 - val_loss: 0.5673 - lr: 3.0000e-04\n",
      "Epoch 19/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1218\n",
      "Epoch 19: loss improved from 0.12212 to 0.12181, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 142ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1218 - val_loss: 0.5583 - lr: 3.0000e-04\n",
      "Epoch 20/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1228\n",
      "Epoch 20: loss did not improve from 0.12181\n",
      "113/113 [==============================] - 16s 140ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1228 - val_loss: 0.5390 - lr: 3.0000e-04\n",
      "Epoch 21/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1092\n",
      "Epoch 21: loss improved from 0.12181 to 0.10924, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 140ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1092 - val_loss: 0.5612 - lr: 3.0000e-04\n",
      "Epoch 22/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1046\n",
      "Epoch 22: loss improved from 0.10924 to 0.10463, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 16s 141ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1046 - val_loss: 0.5597 - lr: 3.0000e-04\n",
      "Epoch 23/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1084\n",
      "Epoch 23: loss did not improve from 0.10463\n",
      "113/113 [==============================] - 16s 143ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1084 - val_loss: 0.5634 - lr: 3.0000e-04\n",
      "Epoch 24/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1095\n",
      "Epoch 24: loss did not improve from 0.10463\n",
      "113/113 [==============================] - 16s 142ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1095 - val_loss: 0.5497 - lr: 3.0000e-04\n",
      "Epoch 25/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1027\n",
      "Epoch 25: loss improved from 0.10463 to 0.10270, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 17s 149ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1027 - val_loss: 0.5536 - lr: 3.0000e-04\n",
      "Epoch 26/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0976\n",
      "Epoch 26: loss improved from 0.10270 to 0.09763, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 17s 147ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0976 - val_loss: 0.5576 - lr: 3.0000e-04\n",
      "Epoch 27/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0983\n",
      "Epoch 27: loss did not improve from 0.09763\n",
      "113/113 [==============================] - 16s 145ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0983 - val_loss: 0.5495 - lr: 3.0000e-04\n",
      "Epoch 28/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1017\n",
      "Epoch 28: loss did not improve from 0.09763\n",
      "113/113 [==============================] - 16s 145ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1017 - val_loss: 0.5544 - lr: 3.0000e-04\n",
      "Epoch 29/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0931\n",
      "Epoch 29: loss improved from 0.09763 to 0.09307, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 17s 150ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0931 - val_loss: 0.5421 - lr: 3.0000e-04\n",
      "Epoch 30/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.1024\n",
      "Epoch 30: loss did not improve from 0.09307\n",
      "113/113 [==============================] - 17s 155ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.1024 - val_loss: 0.5485 - lr: 3.0000e-04\n",
      "Epoch 31/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0974\n",
      "Epoch 31: loss did not improve from 0.09307\n",
      "113/113 [==============================] - 17s 154ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0974 - val_loss: 0.5383 - lr: 3.0000e-04\n",
      "Epoch 32/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0942\n",
      "Epoch 32: loss did not improve from 0.09307\n",
      "113/113 [==============================] - 17s 154ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0942 - val_loss: 0.5455 - lr: 3.0000e-04\n",
      "Epoch 33/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0954\n",
      "Epoch 33: loss did not improve from 0.09307\n",
      "113/113 [==============================] - 17s 153ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0954 - val_loss: 0.5424 - lr: 3.0000e-04\n",
      "Epoch 34/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0891\n",
      "Epoch 34: loss improved from 0.09307 to 0.08908, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 18s 155ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0891 - val_loss: 0.5426 - lr: 3.0000e-04\n",
      "Epoch 35/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0856\n",
      "Epoch 35: loss improved from 0.08908 to 0.08565, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 18s 156ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0856 - val_loss: 0.5340 - lr: 3.0000e-04\n",
      "Epoch 36/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0920\n",
      "Epoch 36: loss did not improve from 0.08565\n",
      "113/113 [==============================] - 17s 154ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0920 - val_loss: 0.5415 - lr: 3.0000e-04\n",
      "Epoch 37/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0938\n",
      "Epoch 37: loss did not improve from 0.08565\n",
      "113/113 [==============================] - 17s 155ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0938 - val_loss: 0.5220 - lr: 3.0000e-04\n",
      "Epoch 38/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0876\n",
      "Epoch 38: loss did not improve from 0.08565\n",
      "113/113 [==============================] - 17s 152ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0876 - val_loss: 0.5391 - lr: 3.0000e-04\n",
      "Epoch 39/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0856\n",
      "Epoch 39: loss improved from 0.08565 to 0.08559, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 18s 157ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0856 - val_loss: 0.5472 - lr: 3.0000e-04\n",
      "Epoch 40/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0889\n",
      "Epoch 40: loss did not improve from 0.08559\n",
      "113/113 [==============================] - 17s 152ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0889 - val_loss: 0.5291 - lr: 3.0000e-04\n",
      "Epoch 41/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0823\n",
      "Epoch 41: loss improved from 0.08559 to 0.08230, saving model to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/checkpoints/cvae_full_extrapol_50.h5\n",
      "113/113 [==============================] - 18s 156ms/step - batch: 56.0000 - size: 1.0000 - loss: 0.0823 - val_loss: 0.5413 - lr: 3.0000e-04\n",
      "Epoch 42/500\n",
      "113/113 [==============================] - ETA: 0s - batch: 56.0000 - size: 1.0000 - loss: 0.0858"
     ]
    }
   ],
   "source": [
    "cvae.optimizer.lr = config[\"CVAE\"][\"learning_rate\"]\n",
    "\n",
    "# Fit the model\n",
    "history = cvae.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=len(train_data_gen),\n",
    "    epochs=epochs,\n",
    "    validation_data=test_data_gen,\n",
    "    validation_steps=len(test_data_gen),\n",
    "    callbacks=[reduce_lr, early_stopping, model_checkpoint, history_logger],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot and save learning curves\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MODE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextrapol\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43msave_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhistory_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATA\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPERCENTAGE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     plot_learning_curves(\n\u001b[1;32m      7\u001b[0m         history,\n\u001b[1;32m      8\u001b[0m         log_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m         plt_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCVAE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPERCENTAGE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m         save_fig\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m MODE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpol\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Projectos/spatiotemporal-vae-reconstruction/notebooks/../src/utils.py:456\u001b[0m, in \u001b[0;36msave_history\u001b[0;34m(history, path)\u001b[0m\n\u001b[1;32m    453\u001b[0m     history_dict[key] \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[key]\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# Save the history to a CSV file\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    458\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved history to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvae/lib/python3.10/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda3/envs/cvae/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvae/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/cvae/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# plot and save learning curves\n",
    "if MODE == \"extrapol\":\n",
    "    save_history(\n",
    "        history, os.path.join(checkpoint_dir, f\"history_{DATA}_{MODE}_{PERCENTAGE}.csv\")\n",
    "    )\n",
    "    # plot_learning_curves(\n",
    "    #     history,\n",
    "    #     log_scale=True,\n",
    "    #     plt_title=f\"CVAE {DATA} {MODE} {PERCENTAGE}\",\n",
    "    #     save_fig=True,\n",
    "    # )\n",
    "\n",
    "elif MODE == \"interpol\":\n",
    "    save_history(history, os.path.join(checkpoint_dir, f\"history_{DATA}_{MODE}.csv\"))\n",
    "    # plot_learning_curves(\n",
    "    #     history, log_scale=True, plt_title=f\"CVAE_{DATA}_{MODE}\", save_fig=True\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load the best model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcvae\u001b[49m\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cvae' is not defined"
     ]
    }
   ],
   "source": [
    "# load the best model\n",
    "cvae.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frames(\n",
    "    decoder, output_dir: str, total_frames: int = 22500, resize_original: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates and saves the frames from a trained decoder.\n",
    "\n",
    "    Parameters:\n",
    "        decoder (keras.Model): The trained decoder.\n",
    "        output_dir (str): The path to the output directory.\n",
    "        total_frames (int): The total number of frames to generate.\n",
    "        resize_original (bool): Whether to resize the frames to the original dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    start_total_time = time.time()\n",
    "\n",
    "    frames_num = np.arange(1, total_frames + 1, 1)\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        frame_num = frames_num[i]\n",
    "\n",
    "        # Sample from the latent space\n",
    "        z_sample = np.full((1, config[\"CVAE\"][\"latent_dim\"]), 0.5)\n",
    "\n",
    "        # Generate the frame\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            reconst = decoder.predict([z_sample, frame_to_label(frame_num)])\n",
    "            reconst_time = (time.time() - start_time) * 1000\n",
    "            reconst = np.squeeze(reconst, axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating frame {frame_num}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if resize_original:\n",
    "            start_time = time.time()\n",
    "            reconst = tf.image.resize(\n",
    "                images=reconst, size=config[\"data\"][\"original_vid_dims\"]\n",
    "            )\n",
    "            resize_time = (time.time() - start_time) * 1000\n",
    "        else:\n",
    "            resize_time = 0.0  # Not resizing\n",
    "\n",
    "        # Binarize the reconstructed image with OpenCV\n",
    "        start_time = time.time()\n",
    "        _, thresh_img = cv2.threshold(\n",
    "            reconst, config[\"CVAE\"][\"threshold\"], 255, cv2.THRESH_BINARY\n",
    "        )\n",
    "        threshold_time = (time.time() - start_time) * 1000\n",
    "\n",
    "        # Save the thresholded image as png in grayscale\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            cv2.imwrite(\n",
    "                os.path.join(output_dir, f\"frame_{frame_num:06d}.png\"), thresh_img\n",
    "            )\n",
    "            save_time = (time.time() - start_time) * 1000\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving frame {frame_num}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Print progress with time information\n",
    "        print(\n",
    "            f\"Generated frame {i+1} of {total_frames} | \"\n",
    "            f\"Reconst: {reconst_time:.2f}ms | \"\n",
    "            f\"Resize: {resize_time:.2f}ms | \"\n",
    "            f\"Threshold: {threshold_time:.2f}ms | \"\n",
    "            f\"Save: {save_time:.2f}ms | \"\n",
    "            f\"Elapsed Time: {time.time() - start_total_time:.2f}s  \",\n",
    "            end=\"\\r\",\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagociic/miniconda3/envs/cvae/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated frame 22500 of 22500 | Reconst: 24.35ms | Resize: 0.00ms | Threshold: 0.10ms | Save: 0.64ms | Elapsed Time: 548.33s  \n"
     ]
    }
   ],
   "source": [
    "output_png_dir = os.path.join(output_dir, \"PNG\")\n",
    "generate_frames(decoder, output_png_dir, total_frames=LAST_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Creating image list...                          \n",
      "INFO - Writing frames to file 1/22500\n",
      "INFO - Writing frames to file 1001/22500\n",
      "INFO - Writing frames to file 2001/22500\n",
      "INFO - Writing frames to file 3001/22500\n",
      "INFO - Writing frames to file 4001/22500\n",
      "INFO - Writing frames to file 5001/22500\n",
      "INFO - Writing frames to file 6001/22500\n",
      "INFO - Writing frames to file 7001/22500\n",
      "INFO - Writing frames to file 8001/22500\n",
      "INFO - Writing frames to file 9001/22500\n",
      "INFO - Writing frames to file 10001/22500\n",
      "INFO - Writing frames to file 11001/22500\n",
      "INFO - Writing frames to file 12001/22500\n",
      "INFO - Writing frames to file 13001/22500\n",
      "INFO - Writing frames to file 14001/22500\n",
      "INFO - Writing frames to file 15001/22500\n",
      "INFO - Writing frames to file 16001/22500\n",
      "INFO - Writing frames to file 17001/22500\n",
      "INFO - Writing frames to file 18001/22500\n",
      "INFO - Writing frames to file 19001/22500\n",
      "INFO - Writing frames to file 20001/22500\n",
      "INFO - Writing frames to file 21001/22500\n",
      "INFO - Writing frames to file 22001/22500\n",
      "INFO - Saved video to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/outputs/CVAE/extrapol/90/unet/video_unet_extrapol_90.mp4\n"
     ]
    }
   ],
   "source": [
    "# generate video from the generated frames\n",
    "if MODE == \"extrapol\":\n",
    "    file_name = f\"video_{DATA}_{MODE}_{PERCENTAGE}\"\n",
    "    title = f\"CVAE: {MODE}ation - {DATA}, {PERCENTAGE}, {config['CVAE']['epochs']} epochs, 10x speed\"\n",
    "elif MODE == \"interpol\":\n",
    "    file_name = f\"video_{DATA}_{MODE}\"\n",
    "    title = f\"CVAE: {MODE}ation - {DATA}, {config['CVAE']['epochs']} epochs, 10x speed\"\n",
    "\n",
    "frames_to_video(\n",
    "    img_list_dir=os.path.join(output_dir, \"PNG\"),\n",
    "    output_dir=output_dir,\n",
    "    output_resolution=config[\"data\"][\"original_vid_dims\"],\n",
    "    title=title,\n",
    "    f_ps=250,  # 10x speed\n",
    "    file_name=file_name,\n",
    "    frame_num_text=True,\n",
    "    font_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Converting masks to polygons...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 22499 masks out of 22500 | Time elapsed: 8369.37s  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Saved polygons to /home/tiagociic/Projectos/spatiotemporal-vae-reconstruction/outputs/CVAE/extrapol/90/unet/WKT/extrapol_unet.wkt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 22500 masks out of 22500 | Time elapsed: 8370.00s  \r"
     ]
    }
   ],
   "source": [
    "# List of generated frames paths\n",
    "msks_paths = sorted(glob(os.path.join(output_png_dir, \"*.png\")))\n",
    "\n",
    "# Convert the masks to polygons and save them as a WKT file\n",
    "masks_to_polygons(\n",
    "    msks_paths,\n",
    "    out_dim=tuple(config[\"data\"][\"original_vid_dims\"]),\n",
    "    save_path=os.path.join(BASE_DIR,\"outputs\", MODEL, MODE, str(PERCENTAGE), DATA, \"WKT\", f\"{MODE}_{DATA}.wkt\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
