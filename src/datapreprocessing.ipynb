{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "from glob import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "from patoolib import extract_archive\n",
    "import importlib\n",
    "\n",
    "import utils             # the module to reload\n",
    "importlib.reload(utils)  # reload the module\n",
    "from utils import wkt2masc, load_images_from_folder\n",
    "\n",
    "import cvae_model_v2             # the module to reload\n",
    "importlib.reload(cvae_model_v2)  # reload the module\n",
    "from cvae_model_v2 import CVAE\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "BASE_DIR = os.path.dirname(current_dir)\n",
    "dataset_dir = os.path.join(BASE_DIR, 'dataset')\n",
    "data_dir = os.path.join(BASE_DIR, 'data')\n",
    "config_file = os.path.join(BASE_DIR, 'config.yml')\n",
    "\n",
    "DATA = \"full\"  # \"full\" or \"sampled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there isn´t unrar installed, install it with: sudo apt-get install unrar (linux)\n",
    "# for windows, install it from: https://www.rarlab.com/rar_add.htm (unrarw32.exe)\n",
    "\n",
    "dataset_path = os.path.join(dataset_dir, \"BurnedAreaUAV_dataset\")\n",
    "if not os.path.exists(dataset_path):\n",
    "    extract_archive(os.path.join(dataset_dir, \"BurnedAreaUAV_dataset_v1.rar\"), program=\"unrar\", outdir=dataset_dir)\n",
    "    os.remove(os.path.join(dataset_dir, \"BurnedAreaUAV_dataset_v1.rar\"))\n",
    "\n",
    "with open(config_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! move images to train and test folders ERRADO!! PRECISAMOS È DAS MASCARAS !!!\n",
    "# dataset_train_imgs_path = os.path.join(dataset_path, 'PNG', 'train', 'frames')\n",
    "# dataset_test_imgs_path = os.path.join(dataset_path, 'PNG', 'test', 'frames')\n",
    "# train_imgs_list = [os.path.basename(x) for x in glob(dataset_train_imgs_path + \"/*.png\")]\n",
    "# test_imgs_list = [os.path.basename(x) for x in glob(dataset_test_imgs_path + \"/*.png\")]\n",
    "# train_imgs_dir = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"images\")\n",
    "# test_imgs_dir = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"images\")\n",
    "\n",
    "# if not os.path.exists(train_imgs_dir):\n",
    "#     os.makedirs(train_imgs_dir)\n",
    "    \n",
    "# if not os.path.exists(test_imgs_dir):\n",
    "#     os.makedirs(test_imgs_dir)\n",
    "\n",
    "# for file_name in train_imgs_list:\n",
    "#     source = os.path.join(dataset_train_imgs_path, file_name)\n",
    "#     destination = os.path.join(train_imgs_dir, file_name)\n",
    "#     os.rename(source, destination)\n",
    "\n",
    "# for file_name in test_imgs_list:\n",
    "#     source = os.path.join(dataset_test_imgs_path, file_name)\n",
    "#     destination = os.path.join(test_imgs_dir, file_name)\n",
    "#     os.rename(source, destination)\n",
    "    \n",
    "# test_imgs_dir = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"images\")\n",
    "# images_test_path = os.path.join(dataset_path, \"BurnedAreaUAV_dataset_v1\", \"/PNG/test/frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks directories creation and conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --------------------------------------\n",
      "    # \u001b[1mProperties of the resulting masks\u001b[0m\n",
      "    # Width: 512, Height: 512\n",
      "    # Number of masks to create: 226\n",
      "    --------------------------------------\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:00<00:00, 555.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --------------------------------------\n",
      "    # \u001b[1mProperties of the resulting masks\u001b[0m\n",
      "    # Width: 512, Height: 512\n",
      "    # Number of masks to create: 23\n",
      "    --------------------------------------\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 560.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --------------------------------------\n",
      "    # \u001b[1mProperties of the resulting masks\u001b[0m\n",
      "    # Width: 512, Height: 512\n",
      "    # Number of masks to create: 13\n",
      "    --------------------------------------\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 571.05it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_train_msks_path = os.path.join(dataset_path, 'PNG', 'train', 'masks')\n",
    "dataset_test_msks_path = os.path.join(dataset_path, 'PNG', 'test', 'masks')\n",
    "train_msks_list = [os.path.basename(x) for x in glob(dataset_train_msks_path + \"/*.png\")]\n",
    "test_msks_list = [os.path.basename(x) for x in glob(dataset_test_msks_path + \"/*.png\")]\n",
    "\n",
    "\n",
    "\n",
    "# convert WKT files to segmentation masks : full train, sampled train and test\n",
    "train_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"masks\")\n",
    "if not os.path.exists(train_masks_dir):\n",
    "    os.makedirs(train_masks_dir)\n",
    "\n",
    "test_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"masks\")\n",
    "if not os.path.exists(test_masks_dir):\n",
    "    os.makedirs(test_masks_dir)\n",
    "\n",
    "sampled_masks_txt_path = os.path.join(BASE_DIR, config[\"data\"][\"sampled_masks_txt\"])\n",
    "with open(sampled_masks_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    polygons = f.readlines()\n",
    "    # extract indexes\n",
    "    indexes = [int(polygon.split(\",\")[0]) for polygon in polygons]\n",
    "\n",
    "train_sampled_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"train_sampled_dir\"], \"masks\")\n",
    "if not os.path.exists(train_sampled_masks_dir):\n",
    "    os.makedirs(train_sampled_masks_dir)\n",
    "\n",
    "wkt2masc(\n",
    "    wkt_file=os.path.join(BASE_DIR, config[\"data\"][\"train_wkt\"]),\n",
    "    images_path=train_masks_dir,\n",
    "    orig_dims=config[\"data\"][\"original_vid_dims\"],\n",
    "    height=config[\"data\"][\"input_size\"][0],\n",
    "    width=config[\"data\"][\"input_size\"][1],\n",
    ")\n",
    "\n",
    "wkt2masc(\n",
    "    wkt_file=os.path.join(BASE_DIR, config[\"data\"][\"test_wkt\"]),\n",
    "    images_path=test_masks_dir,\n",
    "    orig_dims=config[\"data\"][\"original_vid_dims\"],\n",
    "    height=config[\"data\"][\"input_size\"][0],\n",
    "    width=config[\"data\"][\"input_size\"][1],\n",
    ")\n",
    "\n",
    "wkt2masc(\n",
    "    wkt_file=os.path.join(BASE_DIR, config[\"data\"][\"sampled_masks_wkt\"]),\n",
    "    images_path=train_sampled_masks_dir,\n",
    "    orig_dims=config[\"data\"][\"original_vid_dims\"],\n",
    "    height=config[\"data\"][\"input_size\"][0],\n",
    "    width=config[\"data\"][\"input_size\"][1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train masks: 226\n",
      "Train sampled masks: 13\n",
      "Test masks: 23\n"
     ]
    }
   ],
   "source": [
    "# reconstruct the masks labels\n",
    "msks_train_paths = sorted(glob(os.path.join(train_masks_dir, \"*.png\")))\n",
    "msks_train_labels = [int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 for m in msks_train_paths]\n",
    "msks_test_paths = sorted(glob(os.path.join(test_masks_dir, \"*.png\")))\n",
    "msks_test_labels = [int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 + 20250 for m in msks_test_paths]\n",
    "msks_train_sampled_paths = sorted(glob(os.path.join(train_sampled_masks_dir, \"*.png\")))\n",
    "msks_train_sampled_labels = [100 * i for i in indexes]\n",
    "\n",
    "print(\"Train masks:\", len(msks_train_paths))\n",
    "print(\"Train sampled masks:\", len(msks_train_sampled_paths))\n",
    "print(\"Test masks:\", len(msks_test_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load masks and process labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Variable        Shape              Dtype    Max      Min     \n",
      "----------------------------------------------------------\n",
      "train_imgs      (226, 512, 512, 1) float32   1.0 -1.0\n",
      "train_labels    (226, 1)           float32   1.0 0.0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "test_imgs       (23, 512, 512, 1)  float32   1.0 -1.0\n",
      "test_labels     (23, 1)            float32   1.0 0.9\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if DATA == 'full':\n",
    "    TRAIN_DIR = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"masks\")\n",
    "else:\n",
    "    TRAIN_DIR = os.path.join(BASE_DIR, config[\"data\"][\"train_sampled_dir\"], \"masks\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"masks\")\n",
    "\n",
    "# train and test numpy arrays\n",
    "train_masks = load_images_from_folder(TRAIN_DIR, target_size=config[\"data\"][\"input_size\"][:2])\n",
    "test_masks = load_images_from_folder(TEST_DIR, target_size=config[\"data\"][\"input_size\"][:2])\n",
    "\n",
    "# labels normalization and reshaping\n",
    "max_val = np.max(msks_train_labels)\n",
    "train_labels = (msks_train_labels/max_val).astype(np.float32)\n",
    "train_labels = np.expand_dims(train_labels, axis=-1)\n",
    "test_labels = (msks_test_labels/max_val).astype(np.float32)\n",
    "test_labels = np.expand_dims(test_labels, axis=-1)\n",
    "\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'Variable':<15} {'Shape':<18} {'Dtype':<8} {'Max':<8} {'Min':<8}\")\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'train_imgs':<15} {str(train_masks.shape):<18} {str(train_masks.dtype):<8}  {np.max(train_masks):.1f}   {np.min(train_masks):.1f}\")\n",
    "print(f\"{'train_labels':<15} {str(train_labels.shape):<18} {str(train_labels.dtype):<8}  {np.max(train_labels):.1f}   {np.min(train_labels):.1f}\")\n",
    "print(\"~\" * 58)\n",
    "print(f\"{'test_imgs':<15} {str(test_masks.shape):<18} {str(test_masks.dtype):<8}  {np.max(test_masks):.1f}   {np.min(test_masks):.1f}\")\n",
    "print(f\"{'test_labels':<15} {str(test_labels.shape):<18} {str(test_labels.dtype):<8}  {np.max(test_labels):.1f}   {np.min(test_labels):.1f}\")\n",
    "print(\"-\" * 58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Lambda, Input, Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten, Reshape, Concatenate\n",
    "from tensorflow.keras.layers import SeparableConv2D, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(input, filters, f_init=\"he_normal\"):\n",
    "   \"\"\"\n",
    "   Apply two convolutional layers with ReLU activation function.\n",
    "\n",
    "   Args:\n",
    "         input (tensor): Input tensor to the block.\n",
    "         filters (int): Number of filters in the convolutional layers.\n",
    "        \n",
    "   Returns:\n",
    "         tensor: Output tensor of the block with ReLU activation.\n",
    "   \"\"\"   \n",
    "   x = Conv2DTranspose(filters, \n",
    "                     kernel_size = (4,4), \n",
    "                     strides=2,\n",
    "                     kernel_initializer = f_init,\n",
    "                     data_format = \"channels_last\", \n",
    "                     padding=\"same\")(input)\n",
    "\n",
    "   x = SeparableConv2D(filters, \n",
    "                     kernel_size = (4,4), \n",
    "                     depthwise_initializer = f_init,\n",
    "                     pointwise_initializer = f_init,\n",
    "                     padding=\"same\")(x)\n",
    "   x = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "   x = SeparableConv2D(filters, \n",
    "                     kernel_size = (4,4), \n",
    "                     depthwise_initializer = f_init,\n",
    "                     pointwise_initializer = f_init,\n",
    "                     padding=\"same\")(x)\n",
    "   activation = Activation(tf.nn.leaky_relu)(x)\n",
    "   \n",
    "   return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, filters, f_init=\"he_normal\"):\n",
    "    \"\"\"\n",
    "    Apply two convolutional layers with ReLU activation function.\n",
    "\n",
    "    Args:\n",
    "        input (tensor): Input tensor to the block.\n",
    "        filters (int): Number of filters in the convolutional layers.\n",
    "\n",
    "    Returns:\n",
    "        tensor: Output tensor of the block with ReLU activation.\n",
    "    \"\"\"\n",
    "    x = SeparableConv2D(filters, \n",
    "                        kernel_size = (4,4), \n",
    "                        depthwise_initializer = f_init,\n",
    "                        pointwise_initializer = f_init,\n",
    "                        padding=\"same\")(input)\n",
    "    x = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    x = SeparableConv2D(filters, \n",
    "                        kernel_size = (4,4), \n",
    "                        depthwise_initializer = f_init,\n",
    "                        pointwise_initializer = f_init,\n",
    "                        padding=\"same\")(x)\n",
    "    ativ = Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "    m_pool = MaxPooling2D(pool_size=(2, 2),\n",
    "                          strides=2,\n",
    "                          data_format=\"channels_last\",\n",
    "                          padding='same')(ativ)\n",
    "    \n",
    "    return m_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 64)\n",
      "(None, 128, 128, 32)\n",
      "(None, 524288)\n",
      "Model: \"cvae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " encoder (Functional)        [(None, 64),                 3357281   ['input_2[0][0]']             \n",
      "                              (None, 64),                 6                                       \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " label (InputLayer)          [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " decoder (Functional)        (None, 512, 512, 1)          1749779   ['encoder[0][2]',             \n",
      "                                                          3          'label[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51070609 (194.82 MB)\n",
      "Trainable params: 51070609 (194.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "H, W, C = config[\"data\"][\"input_size\"]\n",
    "\n",
    "#--------\n",
    "# Encoder\n",
    "#--------\n",
    "\n",
    "encoder_inputs = Input(shape=(H, W, C))\n",
    "# Reshape input to 2D image\n",
    "\n",
    "x = conv_block(encoder_inputs, \n",
    "               config[\"CVAE\"][\"ref_filters\"]*2, \n",
    "               config[\"CVAE\"][\"w_init\"])\n",
    "print(x.shape)\n",
    "x = conv_block(x, \n",
    "               config[\"CVAE\"][\"ref_filters\"]*1, \n",
    "               config[\"CVAE\"][\"w_init\"])\n",
    "print(x.shape)\n",
    "x = Flatten()(x)\n",
    "print(x.shape)\n",
    "x = Dense(64, activation=\"leaky_relu\")(x)\n",
    "\n",
    "# VAE specific layers for mean and log variance\n",
    "z_mean = Dense(config[\"CVAE\"][\"latent_dim\"],  activation=\"relu\", name=\"z_mean\")(x)\n",
    "z_log_var = Dense(config[\"CVAE\"][\"latent_dim\"], activation=\"relu\", name=\"z_log_var\")(x)\n",
    "\n",
    "# Sampling layer to sample z from the latent space\n",
    "z = Lambda(sampler, output_shape=(config[\"CVAE\"][\"latent_dim\"],), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# Instantiate encoder model\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "#--------\n",
    "# Decoder\n",
    "#--------\n",
    "\n",
    "latent_inputs = Input(shape=(config[\"CVAE\"][\"latent_dim\"],), name='z_sampling')\n",
    "label_inputs = Input(shape=(len(train_labels[0]),), name='label')\n",
    "decoder_inputs = Concatenate()([latent_inputs, label_inputs])\n",
    "x = Dense(64*64*64, activation=\"relu\")(decoder_inputs)\n",
    "x = Reshape((128,128,16))(x)\n",
    "x = deconv_block(x, config[\"CVAE\"][\"ref_filters\"]*2, \n",
    "                 config[\"CVAE\"][\"w_init\"])\n",
    "x = deconv_block(x, config[\"CVAE\"][\"ref_filters\"]*4, \n",
    "                 config[\"CVAE\"][\"w_init\"])\n",
    "decoder_output = Conv2DTranspose(1, 3, activation=\"tanh\", padding=\"same\")(x)\n",
    "\n",
    "# decoder_output = Reshape(INPUT_SHAPE)(x)\n",
    "\n",
    "decoder = Model([latent_inputs, label_inputs], decoder_output, name=\"decoder\")\n",
    "\n",
    "#-----------------\n",
    "# Conditional VAE\n",
    "#-----------------\n",
    "\n",
    "outputs = decoder([encoder(encoder_inputs)[2], label_inputs])\n",
    "cvae = Model([encoder_inputs, label_inputs], outputs, name='cvae')\n",
    "cvae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_kl_loss(y_true, y_pred, beta: float = 1.0):\n",
    "    \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "    # E[log P(X|z)]\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    recontruction = tf.reduce_mean(squared_difference, axis=-1)\n",
    "    # D_KL(Q(z|X) || P(z|X)); calculate in closed from as both dist. are Gaussian\n",
    "    kl_divergence = 0.5 * tf.reduce_sum(tf.exp(z_log_var) + tf.square(z_mean) - 1. - z_log_var, axis=-1)\n",
    "    return recontruction + beta*kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate = 3e-4),\n",
    "             loss=mse_kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 203 samples, validate on 23 samples\n",
      "Epoch 1/20\n",
      "203/203 [==============================] - 37s 178ms/sample - loss: 0.6693 - val_loss: 0.3755\n",
      "Epoch 2/20\n",
      "203/203 [==============================] - 36s 178ms/sample - loss: 0.2739 - val_loss: 0.4358\n",
      "Epoch 3/20\n",
      "203/203 [==============================] - 36s 179ms/sample - loss: 0.2284 - val_loss: 0.3978\n",
      "Epoch 4/20\n",
      "203/203 [==============================] - 36s 180ms/sample - loss: 0.2109 - val_loss: 0.4433\n",
      "Epoch 5/20\n",
      "203/203 [==============================] - 37s 180ms/sample - loss: 0.2009 - val_loss: 0.3469\n",
      "Epoch 6/20\n",
      "203/203 [==============================] - 36s 180ms/sample - loss: 0.1910 - val_loss: 0.3170\n",
      "Epoch 7/20\n",
      "203/203 [==============================] - 36s 179ms/sample - loss: 0.1746 - val_loss: 0.2994\n",
      "Epoch 8/20\n",
      "203/203 [==============================] - 36s 179ms/sample - loss: 0.1755 - val_loss: 0.3147\n",
      "Epoch 9/20\n",
      "203/203 [==============================] - 36s 179ms/sample - loss: 0.1672 - val_loss: 0.3011\n",
      "Epoch 10/20\n",
      "203/203 [==============================] - 36s 178ms/sample - loss: 0.1589 - val_loss: 0.2872\n",
      "Epoch 11/20\n",
      "203/203 [==============================] - 34s 166ms/sample - loss: 0.1587 - val_loss: 0.3047\n",
      "Epoch 12/20\n",
      "203/203 [==============================] - 33s 163ms/sample - loss: 0.1612 - val_loss: 0.3075\n",
      "Epoch 13/20\n",
      "203/203 [==============================] - 35s 175ms/sample - loss: 0.1584 - val_loss: 0.2798\n",
      "Epoch 14/20\n",
      "203/203 [==============================] - 36s 179ms/sample - loss: 0.1478 - val_loss: 0.2746\n",
      "Epoch 15/20\n",
      "203/203 [==============================] - 37s 180ms/sample - loss: 0.1491 - val_loss: 0.2788\n",
      "Epoch 16/20\n",
      "203/203 [==============================] - 37s 180ms/sample - loss: 0.1504 - val_loss: 0.2912\n",
      "Epoch 17/20\n",
      "203/203 [==============================] - 37s 181ms/sample - loss: 0.1419 - val_loss: 0.2671\n",
      "Epoch 18/20\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.1481"
     ]
    }
   ],
   "source": [
    "history = cvae.fit([train_masks, train_labels],\n",
    "                     train_masks,\n",
    "                     epochs=20,\n",
    "                     batch_size=1,\n",
    "                     validation_split=0.1\n",
    "                     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
