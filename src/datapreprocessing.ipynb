{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "from patoolib import extract_archive\n",
    "import importlib\n",
    "import utils  # the module you want to reload\n",
    "\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import wkt2masc, load_images_from_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"full\"  # \"full\" or \"sampled\"\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "BASE_DIR = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(BASE_DIR, 'data')\n",
    "config_file = os.path.join(BASE_DIR, 'config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --------------------------------------\n",
      "    # \u001b[1mProperties of the resulting masks\u001b[0m\n",
      "    # Width: 512, Height: 512\n",
      "    # Number of masks to create: 226\n",
      "    --------------------------------------\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:00<00:00, 649.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --------------------------------------\n",
      "    # \u001b[1mProperties of the resulting masks\u001b[0m\n",
      "    # Width: 512, Height: 512\n",
      "    # Number of masks to create: 23\n",
      "    --------------------------------------\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 620.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --------------------------------------\n",
      "    # \u001b[1mProperties of the resulting masks\u001b[0m\n",
      "    # Width: 512, Height: 512\n",
      "    # Number of masks to create: 13\n",
      "    --------------------------------------\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 540.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# if there isn´t unrar installed, install it with: sudo apt-get install unrar (linux)\n",
    "# for windows, install it from: https://www.rarlab.com/rar_add.htm (unrarw32.exe)\n",
    "\n",
    "dataset_path = os.path.join(data_dir, \"BurnedAreaUAV_dataset\")\n",
    "if not os.path.exists(dataset_path):\n",
    "    extract_archive(os.path.join(data_dir, \"BurnedAreaUAV_dataset_v1.rar\"), program=\"unrar\", outdir=data_dir)\n",
    "\n",
    "with open(config_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "sampled_masks_txt_path = os.path.join(BASE_DIR, config[\"data\"][\"sampled_masks_txt\"])\n",
    "\n",
    "# move images to train and test folders\n",
    "dataset_train_imgs_path = os.path.join(dataset_path, 'PNG', 'train', 'frames')\n",
    "dataset_test_imgs_path = os.path.join(dataset_path, 'PNG', 'test', 'frames')\n",
    "\n",
    "train_imgs_list = [os.path.basename(x) for x in glob(dataset_train_imgs_path + \"/*.png\")]\n",
    "test_imgs_list = [os.path.basename(x) for x in glob(dataset_test_imgs_path + \"/*.png\")]\n",
    "\n",
    "train_imgs_dir = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"images\")\n",
    "test_imgs_dir = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"images\")\n",
    "\n",
    "if not os.path.exists(train_imgs_dir):\n",
    "    os.makedirs(train_imgs_dir)\n",
    "    \n",
    "if not os.path.exists(test_imgs_dir):\n",
    "    os.makedirs(test_imgs_dir)\n",
    "    \n",
    "for file_name in train_imgs_list:\n",
    "    source = os.path.join(dataset_train_imgs_path, file_name)\n",
    "    destination = os.path.join(train_imgs_dir, file_name)\n",
    "    os.rename(source, destination)\n",
    "\n",
    "for file_name in test_imgs_list:\n",
    "    source = os.path.join(dataset_test_imgs_path, file_name)\n",
    "    destination = os.path.join(test_imgs_dir, file_name)\n",
    "    os.rename(source, destination)\n",
    "    \n",
    "test_imgs_dir = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"images\")\n",
    "images_test_path = os.path.join(dataset_path, \"BurnedAreaUAV_dataset_v1\", \"/PNG/test/frames\")\n",
    "\n",
    "with open(sampled_masks_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    polygons = f.readlines()\n",
    "    # extract indexes and polygons\n",
    "    indexes = [int(polygon.split(\",\")[0]) for polygon in polygons]\n",
    "    # polygons = [polygon.split(\",\", 1)[1][:-1] for polygon in polygons]\n",
    "\n",
    "# convert WKT files to segmentation masks : full train, sampled train and test\n",
    "train_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"masks\")\n",
    "if not os.path.exists(train_masks_dir):\n",
    "    os.makedirs(train_masks_dir)\n",
    "\n",
    "test_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"masks\")\n",
    "if not os.path.exists(test_masks_dir):\n",
    "    os.makedirs(test_masks_dir)\n",
    "\n",
    "train_sampled_masks_dir = os.path.join(BASE_DIR, config[\"data\"][\"train_sampled_dir\"], \"masks\")\n",
    "if not os.path.exists(train_sampled_masks_dir):\n",
    "    os.makedirs(train_sampled_masks_dir)\n",
    "\n",
    "wkt2masc(\n",
    "    wkt_file=os.path.join(BASE_DIR, config[\"data\"][\"train_wkt\"]),\n",
    "    images_path=train_masks_dir,\n",
    "    orig_dims=config[\"data\"][\"original_vid_dims\"],\n",
    "    height=config[\"data\"][\"input_size\"][0],\n",
    "    width=config[\"data\"][\"input_size\"][1],\n",
    ")\n",
    "\n",
    "wkt2masc(\n",
    "    wkt_file=os.path.join(BASE_DIR, config[\"data\"][\"test_wkt\"]),\n",
    "    images_path=test_masks_dir,\n",
    "    orig_dims=config[\"data\"][\"original_vid_dims\"],\n",
    "    height=config[\"data\"][\"input_size\"][0],\n",
    "    width=config[\"data\"][\"input_size\"][1],\n",
    ")\n",
    "\n",
    "wkt2masc(\n",
    "    wkt_file=os.path.join(BASE_DIR, config[\"data\"][\"sampled_masks_wkt\"]),\n",
    "    images_path=train_sampled_masks_dir,\n",
    "    orig_dims=config[\"data\"][\"original_vid_dims\"],\n",
    "    height=config[\"data\"][\"input_size\"][0],\n",
    "    width=config[\"data\"][\"input_size\"][1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the masks labels\n",
    "msks_train_paths = sorted(glob(os.path.join(train_masks_dir, \"*.png\")))\n",
    "msks_train_labels = [int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 for m in msks_train_paths]\n",
    "msks_train_sampled_paths = sorted(glob(os.path.join(train_sampled_masks_dir, \"*.png\")))\n",
    "msks_train_sampled_labels = [100 * i for i in indexes]\n",
    "msks_test_paths = sorted(glob(os.path.join(test_masks_dir, \"*.png\")))\n",
    "msks_test_labels = [int(os.path.basename(m).split(\"_\")[1].split(\".\")[0]) * 100 + 20250 for m in msks_test_paths]\n",
    "\n",
    "print(\"Train masks:\", len(msks_train_paths))\n",
    "print(\"Train sampled masks:\", len(msks_train_sampled_paths))\n",
    "print(\"Test masks:\", len(msks_test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_imgs.shape: (226, 512, 512, 3), train_labels.shape: (226, 1)\n",
      "test_imgs.shape: (23, 512, 512, 3), test_labels.shape: (23, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load images and masks\n",
    "\n",
    "# data/BurnedAreaUAV_dataset/PNG/train/frames\n",
    "if DATA == 'full':\n",
    "    TRAIN_DIR = os.path.join(BASE_DIR, config[\"data\"][\"train_dir\"], \"images\")\n",
    "else:\n",
    "    TRAIN_DIR = os.path.join(BASE_DIR, config[\"data\"][\"train_sampled_dir\"], \"images\")\n",
    "    \n",
    "train_imgs = load_images_from_folder(TRAIN_DIR, target_size=config[\"data\"][\"input_size\"])\n",
    "test_imgs = load_images_from_folder(os.path.join(BASE_DIR, config[\"data\"][\"test_dir\"], \"images\"), \n",
    "                                    target_size=config[\"data\"][\"input_size\"])\n",
    "\n",
    "max_val = np.max(msks_train_labels)\n",
    "train_labels = (msks_train_labels/max_val).astype(np.float32)\n",
    "train_labels = np.expand_dims(train_labels, axis=-1)\n",
    "\n",
    "test_labels = (msks_test_labels/max_val).astype(np.float32)\n",
    "test_labels = np.expand_dims(test_labels, axis=-1)\n",
    "\n",
    "print(f\"train_imgs.shape: {train_imgs.shape}, train_labels.shape: {train_labels.shape}\")\n",
    "print(f\"test_imgs.shape: {test_imgs.shape}, test_labels.shape: {test_labels.shape}\")\n",
    "\n",
    "# train_imgs = train_imgs.reshape((-1, config[\"data\"][\"input_size\"][0]*config[\"data\"][\"input_size\"][1]))\n",
    "# test_imgs = test_imgs.reshape((-1, config[\"data\"][\"input_size\"][0]*config[\"data\"][\"input_size\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs.shape: (13, 262144), train_labels.shape: (13, 1)\n",
    "# test_imgs.shape: (23, 262144), test_labels.shape: (23, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
